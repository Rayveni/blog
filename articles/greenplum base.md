# GreenPlum базовый уровень

## Введение
**GreenPlum** - MPP реляционная *транзакционная* СУБД для хранилищ данных с гибкой горизонтальной масштабируемостью и столбцовым хранением данных на основе PostgreSQL.

![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/intro_cluster.png?raw=true)
Особенностью массово-параллельной архитектуры (Massive parallel processing, MPP) является физическое разделение памяти узлов, объединенных в кластер.
 В случае MPP-СУБД каждый узел кластера работает со только своими жесткими дисками, распараллеливая операции чтения и записи данных.

**Основное предназначение**-выполнение сложных запросов аналитического профиля (OLAP) с большими объёмами структурированных данных.
Как следствие MPP архитектуры ,**GreenPlum**  обеспечивает:
 - быстроту обработки обработки данных(по сути заточен на эффективное выполния операции **full scan** -полное чтение данных из таблицы)
 -  простоту горизонтального масштабирования (с ростом числа  узлов кластера получаем линейный рост производительности), то только при условии равномерного распределения данных по узлам кластера(что не всегда тривиальная задача)
 - несмотря на то, что GreenPlum поддерживает OLTP  нагрузки(OLTP-обработка транзакций в реальном времени),при операции чтения/записи выполняется ряд дополнительных шагов(распределение данных по узлам и т.д.) что делает GreenPlum  не самым лучшим решением.

Лучше всего GreenPlum применять для:
 - построения хранилища с объёмом данных >1 ТБ
 - когда важна надежность и скорость обработки SQL запросов
 - требуется транзакционность(GreenPlum –транзакционная СУБД)

GreenPlum - opensource MPP  решение(в отличие от teradata  и vertica).
**Arenadata**-коммерческий дистрибутив greenplum ,адаптация GreenPlum  для  российского рынка. (добавление фич по администрированию и развертыванию)
| Функционал |Opensource дистрибутив  |ADB CE|ADBE EE
|--|--|--|--|
|<ul><li>Core функционал</li><li>PFX </li><li>gpbackup </li><li>Коннекторы Greenplum<->Hadoop и GreenPlum<->JDBC-источники</li></ul> | + |+ |+|
| Коннекторы GreenPlum<->Kafka и GreenPlum->ClickHouse | - |- |+|
| <ul><li>Command Center(мониторинг на уровне запросов)</li><li>оффлайн установка</li></ul> | - |- |+|
| <ul><li>Управление деплоем и апгрейдом</li><li>Расширение кластера</li><li>Мониторинг&alerting</li></ul> | - |+ |+|
| Client/Loader утилиты | - |- |RedHat B|
| Документация| English only |+ |+|
| <ul><li>Поддержка</li><li>Обучение по продуктам</li></ul> | - |- |+|
| Операционная система| Ubuntu18.04/Redhat 6/Redhat 7 |CentOS 7/Redhat 7 |CentOS 7/Redhat 7/Альт8 СП Сервер|
| Доп.консалтинговые услуги(DBAaS,Smart Start,TAM,Аудит| - |- |+|

## Архитектура и принципы
Кластер Greenplum представляет собой несколько экземпляров (инстансов, instance) объектно-реляционной базы данных PostreSQL, которые работают вместе как единая СУБД.
![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/greenplum-architecture.png?raw=true)

Кластер GreenPlum состоит из 1 управляющего сервера (Master  host), где развернут главный инстанс  PostgreSQL (Master  instance),являющегося точкой входа в GreenPlum  и , присоединенных к нему (в кол-ве не менее 2 шт) сегментных серверов через interconnect(с пропускной способностью не менее 10 Гигабит)

По умолчанию используется UDP (своя реализация TCP over UDP), можно переключить на обычный TCP

Резервный мастер (**Secondary  master  instance**) — инстанс  PostgreSQL, который вручную включается в работу при отказе основного мастера.

Сервер-сегмент (**Segment  host**), который хранит и обрабатывает данные.
Segment  host  Greenplum содержат, в свою очередь, на "ячейки" :(**primary**) и зеркальные (**mirror**) сегменты ,которые представляют собой инстансы  PostgreSQL .

 Каждая ячейка сегментов Greenplum – это независимая база данных PostgreSQL, где хранится часть данных. Primary-сегмент обрабатывает локальные данные, отдавая результаты мастеру. 
 Каждому **primary**-сегменту соответствует свое зеркало (**Mirror**  segment  instance) — инстанс  PostgreSQL, который автоматически включается в работу при отказе primary.
 На **master host** данные не хранятся.
Кластер работает со скоростью самого медленного primary сегмента, соответсвенно необходимо, чтобы:
 - сегментные сервера были одинаковы по мощности
 - кол-во primary сегментов на сегментых серверах должно быть одинаково
 
Master host обычно делают в 2ое слабее сегментного сервера.Если есть выбор между малых кол-вом мощных сегментых серверов и большим кол-вом более слабых, второй вариант как правило предпочтительнее.
![enter image description here](https://www.bigdataschool.ru/wp-content/uploads/2020/05/mpp_1.png)

 1. К кластеру можем подключиться через Postgress совместимый клиент, ODBC/JDBC  подключения к  Master Host.
 2. мастер аутентифицирует клиентские соединения и обрабатывает входящие SQL-запросы
 3. для обработки запроса в каждой базе данных сегмента создаются соответствующие процессы;
 4. после выполнения вычислений над локальными данными каждый сегмент возвращает результаты мастеру;
 5. мастер координирует результаты от сегментов и представляет конечный итог клиентской программе(при необходимости применяя агрегацию и объединение данных).
 
 ### Организация данных
 Каждая таблица присутсвует на всех сегментах кластера (в том числе и на master).Данные хранятся на primary сегментах, **на master данные не хранятся**.
 Иными словами:каждая таблица представлена в виде (N+1) таблиц на всех сегментах кластера, где N – число сегментов + 1 таблица на мастере, где нет пользовательских данных. На каждом сегменте хранится 1/N строк таблицы.
Логика распределения данных задаётся при помощи ключа распределения и необходимо стремиться к максимально равномерному распределению данных.
Соответсвенно максимальную производительность получаем когда:
 - данные распределены равномеро по primary  сегмент
 - участвующие в запросе данные находятся на одном сегменте(например при join таблиц , например с заказами и деталями заказов, "кусочки обеих таблиц" находятся на одном сегменте и могут быть соединены локально)

Понятно, что произвести вычисления локально на сегментах удаётся не всегда, и соотвественно возникают в кластере движения данных:

 - **Gather  motion**  —  объединение результатов выполнения запросов со всех сегментов в один поток (как правило, на мастер).Две таблицы, распределенные по одному ключу, который используется для джойна, выполняют все операции на сегментах, без перемещения данных. В противном случае происходит Broadcast  motion или Redistribution  motion
 - **Broadcast  motion** — каждый сегмент отправляет свою копию данных на другие сегменты. В идеальной ситуации бродкаст происходит только для маленьких таблиц.
 - **Redistribution  motion** — для соединения больших таблиц, распределенных по разным ключам, выполняется перераспределение с целью выполнения соединений локально. Для больших таблиц может быть достаточно затратной операцией.

**Broadcast**  и **Redistribution** достаточно невыгодные операции. Они выполняются при каждом запуске запроса. Рекомендуется избегать их. Увидев в плане запроса такие пункты, стоит обратить внимание на ключи распределения. Также операции distinct и union являются причиной motions.

## Типы таблиц в GreenPlum
![enter image description here](https://i.ibb.co/M6rQgqm/1.png)
Таблицы в GreenPlum  делятся на:

 - **Heap**(унаследованы от Postgres) -подходит для обработки транзакций в реальном времени (OLTP), когда данные в таблицах часто обновляются операциями INSERT, UPDATE и DELETE.  
Используется по умолчанию при создании таблиц.
 - **Append Optimized**-подходят для аналитической обработки больших массивов данных (OLAP), когда данные загружаются большими пакетами и над ними производятся только операции чтения. Операции UPDATE и DELETE не разрешены в Greenplum  над таблицами такого типа.

### Типы хранения данных
 - строчный- каждая строка хранится как непрерывная запись на диске
 ![enter image description here](https://i.onthe.io/smngoz1f6s0ltqojd.7eae6de1.jpg)
 - колоночный-все ячейки, относящиеся к колонке, как непрерывную запись.t
 Колоночное хранение данных значительно снижает затраты на чтение и запись, когда запрос обращается только к небольшому количеству столбцов из множества всех полей таблицы. Такие таблицы также лучше поддаются сжатию.![enter image description here](https://i.onthe.io/smngoz2c530uatfv8.3cca943d.jpg)

### Сжатие данных
Heap таблицы поддреживают только строчный вариант, в то время как AppendOptimized  поддерживают оба(строчный и колоночный).

 - Сжимать данные можно только в Append Optimized (AO)-таблицах.  
 - Тип истепень сжатия изменить после создания таблицы нельзя.
 - Для строковых (ROW-oriented) доступно два кодека: ZLIB и ZSTD.  
 - Для колоночных (COLUMN-oriented) доступно три: ZLIB, ZSTD, RLE. 
 - Используя сжатие, вы получаете экономию по памяти, тратя ресурс CPU. 
 - Уровень сжатия выше 5 на практике не эффективен, накладные расходы по CPU превышают пользу от экономии дискового пространства.  
 - Дляподавляющего большинства задач лучшим будет сжатие ZSTD с уровнем 1(соизмеримый ZLIB с уровнем 5).  
 - Данные на практике сжимаются хорошо,самый негативный сценарий – сжатие вдвое, обычно получается сжать в
   5-7 раз (и даже выше для банковских данных).  
- RLE иногда даёт огромный прирост, если кардинальность(уникальности значений , содержащихся в столбце) данных в столбце низкая.

## Распределение данных
Каждая таблица размещается на всех сегментах кластера. Одна строка может храниться только на одном primary-сегменте (за исключением replicated  таблиц). Необходимо стремиться к равномерному распределению данных по сегментам.
### Виды распределения

 - **DISTRIBUTED RANDOMLY** – планировщик сам раскидывает строки, используя алгоритм round-robin.  
  - **DISTRIBUTED BY** (column(s)) – строка направляется на конкретный сегмент по хешу ключа.
 Как правило,стремятся распределить по часто встречающимся в join атрибутах. 
	   - Не выбирайте для ключей дистрибуции поля, записи в которых распределены сильно неравномерно 
	   - **Не выбирайте даты**.  
	   - Не выбирайте поля, где может быть большое число значений NULL.  
	   - Не выбирайте поля, в последующем
   распределении которых вы не уверены. 
	   - Выбирайте поля, по которым с большой вероятностью будут join ить.
- **DISTRIBUTED REPLICATED** – полная копия
   таблицы хранится на каждом сегменте.Такие таблицы не могут быть партициированы, занимают больше места на кластере , но позволяют  избежать redistribution motion.

В каждой таблице (кроме replicated-таблиц) есть скрытое поле **gp_segment_id**, которое содержит content того сегмента, на котором находится запись.
Если тип распределения не указать, таблица распределится по ключу в виде первой колонки.  
**Это плохая практика, всегда указывайте политику при создании таблицы.**

#### Примеры
##### Создание таблиц распредленных случайно и по ключам
```sql
create table student60.test_table (
 id int,
 data int
)
distributed  randomly;
```
```sql
create table test_table(
    id INT, 
    num INT,
    data INT
)
distributed by (id,num);
```
##### Анализ распределения таблиц
```sql
select gp_segment_id,
       count(*) as records_per_sergment
from student60.test_table
group by gp_segment_id;
```
Все таблицы в GreenPlum распределены или реплицированы.
#### Summary
-   Есть три политики распределения: по хешу выбранного ключа, рандомное распределение и полная репликация таблицы.
- Две основные задачи при распределении:
    *  Избежать перекосов в объёме хранимых данных по сегментам.
  *  Минимизировать передачу данных между сегментами при выполнении запросов.
-    Ключ распределения выбирается также таким образом, чтобы он мог использоваться в JOIN-ах.
-   Если подходящий ключ распределения выбрать невозможно, подойдет рандомное распределение, которое эффективно решает первую задачу.
-   Реплицированные таблицы убирают перемещение данных между сегментами, но занимают больше места и медленнее заполняются и обновляются
## Партиции
![enter image description here](https://russianblogs.com/images/7/7765b3765a76ee080024a91435cd3df7.png)
**Партициирование**- разбиение  таблицы на подтаблицы.За счет этого достигается рост производительности(вместо full scan  всей таблицы идет сканирование только подтаблицы(партиции), но надо понимать, что если запросы сканируют таблицу целиком( отсутсвует условие в **where**, позволяющие выделить партиции, то  партиционирование не ускоряет, а **замедляет** производительность.
Для пользователя партициированная таблица не отличается от непартициированной, т.е. партициированная таблица отличается  от обычной лишь логикой огранизации данных.
Партиционирование может быть многоуровневым(не рекомендуется использовать в GreenPlum).
Варианты партиционирования: 

 - RANGE(диапазон)- например (если партициируем дату, можем задать дату начала , дату окончания и шаг(1 месяц) )
 - LIST(список) -явно перечисляем значения

**Примечание**:Партициированная таблица должна быть распределена по ключу или рандомно.
Поддерживает добавление внешних таблиц созданных при помощи протокола pxf(см. раздел  внешние таблицы)
**Не стоит** выбирать одно  и тоже поле для партициирования и распределения.

### default partition 
Позволяет записывать значения, не подходящие под условие партициирования в партицию по умолчанию (в противном случае insert падал бы с ошибкой).

Если default partition была создана, новые партиции не могут быть добавлены(alter table … add partition) так как в этом случае они могли частично совпасть с данными, помещенными в default партицию ранее.
### Партициирование
- Разбивать на разделы нужно только большие таблицы и лишь в том случае, если исключение или сокращение партиций может быть достигнуто на основе критериев SQL-запроса и достигается партиционированием таблицы на основе его предиката.
- Партиционирование по диапазонам(range) предпочтительнее разделения по списку(list).
- Планировщик запросов может выборочно сканировать партиционированные таблицы только если SQL-запрос содержит прямое и простое ограничение таблицы с использованием неизменяемых операторов, таких как =, <, <=,>,> = и <>.
- Выборочное сканирование(**partition elimination**) распознает стабильные (STABLE) и неизменяемые (IMMUTABLE) функции в SQL-запросе, но не определяет изменчивые (VOLATILE).
Например, условие WHERE в выражении date>CURRENT_DATE заставит планировщик запросов выборочно сканировать партиционированную таблицу. Но при использовании того же условия WHERE в выражении time>TIMEOFDAY этого НЕ произойдет. Поэтому важно убедиться, что SQL-запросы выборочно сканируют партиционированные таблицы, удаляя ненужные разделы. Это можно сделать, изучив план запроса EXPLAIN.
#### Примеры
INCLUSIVE/EXCLUSIVE позволяют включать/ исключать концы интервалов
##### RANGE INTERVAL 
```sql
CREATE TABLE sales (id int, date date, amt
decimal(10,2)) 
DISTRIBUTED BY (id)
PARTITION BY RANGE (date)
(START (date '2016-01-01') INCLUSIVE
END (date '2017-01-01') EXCLUSIVE
EVERY (INTERVAL '1 month'));
```
##### RANGE INTERVAL by INT
```sql
CREATE TABLE rank (id int, rank int, year int, 
gender char(1), count int)
DISTRIBUTED BY (id)
PARTITION BY RANGE (year)
(START (2006) END (2016) EVERY (1),
DEFAULT PARTITION extra);
```
##### RANGE INDIVIDUALLY
```sql
CREATE TABLE sales (id int, date date, amt
decimal(10,2))
DISTRIBUTED BY (id)
PARTITION BY RANGE (date)
(PARTITION Jan16 START (date '2016-01-01') INCLUSIVE,
PARTITION Feb16 START (date '2016-02-01') INCLUSIVE,
PARTITION Mar16 START (date '2016-03-01') INCLUSIVE,
PARTITION Apr16 START (date '2016-04-01') INCLUSIVE,
PARTITION May16 START (date '2016-05-01') INCLUSIVE,
PARTITION Jun16 START (date '2016-06-01') INCLUSIVE 
END (date '2016-07-01') EXCLUSIVE);
```
#####  LIST
```sql
CREATE TABLE rank (id int, rank int, year int, 
gender
char(1), count int )
DISTRIBUTED BY (id)
PARTITION BY LIST (gender)
( PARTITION girls VALUES ('F'),
PARTITION boys VALUES ('M'),
DEFAULT PARTITION other);
```
## Индексы

**Индекс** – объект в СУБД, создаваемый с целью повышения производительности при выборке данных с условиями.

Таблицы в базе данных могут иметь большое количество строк, которые хранятся в произвольном порядке, и их поиск по заданному критерию путём последовательного просмотра таблицы строка за строкой может занимать много времени. Индекс формируется из значений **одного** или **нескольких** столбцов таблицы и указателей на соответствующие строки таблицы и, таким образом, позволяет искать строки, удовлетворяющие критерию поиска. 
Ускорение работы с использованием индексов достигается в первую очередь за счёт того, что индекс имеет структуру, оптимизированную под поиск.

В текущей реализации GreenPlum  пользоваться индексами нужно крайне осторожно (операции добавления/удаления записей/ поддержки индекса стоят дорого) , как правило, механизмов **распределения** и **партициирования** достаточно для большинства задач.

 При загрузке данных в таблицу с индексами удалите индексы, загрузите данные, затем создайте 
индексы заново. Это будет быстрее, чем загружать данные в таблицу сразу.
```sql
CREATE [UNIQUE] INDEX name ON table
[USING btree|bitmap|gist|spgist|gin]
( {column_name | (expression)} [COLLATE parameter] [opclass] [ ASC | DESC ]
[ NULLS { FIRST | LAST } ] [, ...] )
[ WITH ( storage_parameter = value [, ... ] ) ]
[TABLESPACE tablespace]
[WHERE predicate] 
```
## Транзакции
DML-операции (Data Manipulation Language) — команды позволяющие храненить, извлекать, измененять, удаленять и обновлть данные(UDDATE/INSERT/DELETE ,etc).

Во время выполнения DML-операции (или группы операций) может произойти ошибка или сбой и соответсвенно необходим механизм для отката данной операции.
В БД данным механизмом является транзакция.

![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/transaction.jpg?raw=true)
**Транзакция** - группа последовательных операций, представляющую собой логическую единицу работы с данными и служащая для перевода БД из одного непротиворечивого состояния в другое.


 - суть транзакции: объединение последовательных DML операций в одну, по принципу “Все или ничего”
 - промежуточные состояния не видны другим транзакциям
 - в случае ошибки, откатываются все изменения  

Иными словами это группа операций на чтение/запись, выполняющихся только если все операции из группы успешно выполнены.
### Синтаксис
```sql
--начало транзации
begin;
/*  блок транзакции, например:
update ...;
insert....;
delete ...;
*/
--завершение транзации
commit;
```
 -  BEGIN или START TRANSACTION - начало транзакции
 - END или COMMIT - фиксация изменений
 - ROLLBACK - откат всех изменений транзакции
 - SAVEPOINT - ставит метку в транзакции для возможности частичного отката. Можно откатить изменения сделанные после этой метки, не затрагивая изменений сделанных до этой метки
 - ROLLBACK TO SAVEPOINT - откат к ранее установленной метке
 - RELEASE TO SAVEPOINT - удаляет метку

По умолчанию включен режим AUTOCOMMIT. Для отключения, необходимо явно указывать начало и конец транзакции.  
Транзакции не разрешены внутри хранимых процедур. Вся хранимая процедура выполнятся в рамках одной транзакции.

## ACID
ACID - набор требований набор требований к транзакционной, обеспечивающий наиболее надёжную и предсказуемую её работу
 - **A**tomicity  (атомарность ) - Выполняются либо все операции, либо ни одной
 - **C**onstistency (согласованность) - БД сохраняет согласованность при успешном завершении транзакции (т.е фиксации результатов операции)
 - **I**solation (Изолированность) - При выполнении транзакции другие параллельные транзакции с теми же данными не оказывают влияние не ее результат. Полная изолированность - это дорогое требование, поэтому существуют разные режимы неполной изоляции транзакций
 - **D**urability (стойкость) - Даже при сбоях оборудования изменения, сделанные успешно завершенной транзакцией, сохраняются
 
В GreenPlum для реализации Изоляции транзаций используются 2  механизма:
 - MVCC
 - блокировки
### MVCC
В Greenplum  используется унаследованная от Postgress модель **MVCC** (Multiversion Concurrency Control)-многоверсионное управление  параллельным доступом). Это означает, что каждый SQL-оператор видит snapshot данных (_версию базы данных_) на определённый момент времени, вне зависимости от текущего состояния данных. 

В таблицах находятся следующие системные поля:
 - xmin-  номер транзации, добавившей запись
 - xmax- номер транзации, удалившей запись(значение 0  по умолчанию)
```sql
select xmin
      ,xmax
      ,* 
from <table>;
```
Посмотреть удаленные строки можно при помощи gp_select_invisible:
```sql
set gp_select_invisible=true;
select xmin
      ,xmax
      ,* 
from <table>;
```
Удалённые или устаревшие в результате обновления строки, физически не удаляются из таблицы; они сохраняются в ней, пока не будет выполнена команда `VACUUM`.
Основное преимущество использования модели MVCC по сравнению с блокированием заключается в том, что блокировки MVCC, полученные для чтения данных, не конфликтуют с блокировками, полученными для записи, и поэтому чтение никогда не мешает записи, а запись чтению.
### Блокировки в  GreenPlum
Блокировки- выстраивание транзакций в очередь при работе с объектом БД( после выполнения транзакции блокировка снимается и объект доступен для следующей транзакции)
![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/block.png?raw=true)
**Блокировки строк**:
- чтение никогда не блокирует строки
- изменение строки блокирует ее для изменений, но не для чтения

**Блокировки таблиц**:
- запрещают изменения или удаление таблиц, пока с ней идет работа
-  запрещают чтение таблицы при перестроении или перемещении и т.п.

**Рекомендации**:
- выносить операции, требующие ACCESS EXCLUSIVE из длительных транзакций / функций в отдельные транзакции / функции
- ожидающие в очереди блокировки тоже конфликтуют с новыми запросами

**Взаи́мная блокиро́вка** (deadlock) — ситуация , при которой несколько процессов находятся в состоянии ожидания ресурсов, занятых друг другом, и ни один из них не может продолжать свое выполнение.
В этом случае администратор БД вынужден удалять зависшие транзакции вручную.

![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/deadlock.jpg?raw=true)
В GreenPlum  есть механизм **Global Deadlock Detector** позволяющий  упростить работы с deadlock.
Включается параметром
```
gp_enable_global_deadlock_detector
```
и позволяет:
-  выполнять в разных транзакциях операции UPDATE, DELETE и SELECT...FOR UPDATE для одних и тех же HEAP-таблиц. Уровень блокировки меняется на Row  Exclusive
- при возникновении взаимной блокировки, откатывает одну из транзакций (ту, которая вызвала deadlock).

## Создание таблиц
### Схема базы данных
База данных содержит одну или несколько именованных схем, которые в свою очередь содержат таблицы. 
Схемы также содержат именованные объекты других видов, включая типы данных, функции и операторы. Одно и то же имя объекта можно свободно использовать в разных схемах, например и schema1, и myschema могут содержать таблицы с именем mytable.
 В отличие от баз данных, схемы не ограничивают доступ к данным: пользователь может обращаться к объектам в любой схеме текущей базы данных, если ему назначены соответствующие права.

Есть несколько возможных объяснений, для чего стоит применять схемы:

- Чтобы одну базу данных могли использовать несколько пользователей, независимо друг от друга.
- Чтобы объединить объекты базы данных в логические группы для облегчения управления ими.
- Чтобы в одной базе сосуществовали разные приложения, и при этом не возникало конфликтов имён.

Схемы в некоторым смысле подобны каталогам в операционной системе, но они не могут быть вложенными.

По умолчанию используется схема **public**.(то есть  запрос 
```sql 
select * from <table> 
```
 эквивалентен
```sql
select * from public.<table>
```
Для того , чтобы в каждом объекте бд, участвующем в запросе не указывать явно схему(при условии что все объекты из одной схемы, можно использовать конструкцию **set schema**
```sql
set schema ‘<schema>’;
select * from <table>;
```
что эквивалентно 
```sql
select * from <schema>. <table>;
```
### Синтаксис создания таблиц
Общий синтаксис, ниже рассмотрим отдельно параметры создания.
```sql
CREATE [{TEMPORARY | TEMP} | UNLOGGED] TABLE table_name ( 
[ { column_name data_type [ DEFAULT default_expr ] [column_constraint [ ... ] [ ENCODING (
COMPRESSTYPE={ZLIB | ZSTD | RLE_TYPE | NONE} [COMPRESSLEVEL={0-9} ] [BLOCKSIZE={8192-2097152} ]
)]] 
| table_constraint
| LIKE other_table [{INCLUDING|EXCLUDING} {DEFAULTS|CONSTRAINTS|INDEXES|STORAGE|COMMENTS|ALL}] ...}[, ... ] ] )
[ INHERITS ( parent_table [, ... ] ) ]
[ WITH (
{APPENDOPTIMIZED | APPENDONLY}={TRUE|FALSE} – В конфигурации по умолчанию создаются Heap-таблицы
BLOCKSIZE={8192-2097152}
ORIENTATION={COLUMN|ROW}
CHECKSUM={TRUE|FALSE}
COMPRESSTYPE={ZLIB|ZSTD|RLE_TYPE|NONE}
COMPRESSLEVEL={0-9}
FILLFACTOR={10-100}
OIDS[=TRUE|FALSE])
[ ON COMMIT {PRESERVE ROWS | DELETE ROWS | DROP} ]
[ TABLESPACE tablespace ]
[DISTRIBUTED BY (column, [ ... ] ) | DISTRIBUTED RANDOMLY | DISTRIBUTED REPLICATED ]
[ PARTITION BY partition_type (column)…]
```

|     Параметр             |     Описание                                                                                                                                                                                                                                                                                                                                                                                        |
|--------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|     fillfactor           |     Параметр   для таблиц/индексов, указывающий(в процентах) сколько   оставить неиспользованного дискового пространства на страницу с данными(page).Что позволяет в дальнейшем операции UPDATE затрагивать только одно страницу, что ускоряет подобные операции     Не применим для AO  таблиц                                                                                                     |
|     TEMPORARY \| TEMP    |     Признак   временной таблицы.Временные   таблицы удаляются автоматически в конце сессии или транзакции.                                                                                                                                                                                                                                                                                          |
|     UNLOGGED             |     Позволяет   отключить write-ahead   (WAL) лог, что сильно ускоряет DML  операции. Однако содержимое таблицы не   реплицируется на зеркальные инстансы   сегментов ,Так   же такие таблицы не устойчивы к сбоям(crash-safe)                                                                                                                                                                      |
|     COLLATE              |     Определяет параметры сортировки базы   данных или столбца таблицы либо операцию приведения параметров сортировки при   использовании с выражением строки символов. Именем параметров сортировки   может быть либо имя параметров сортировки Windows, либо имя параметров сортировки SQL                                                                                                         |
|     ON COMMIT            |     Поведение временных таблиц в конце транзакции   может контролироаться ON   COMMIT.      Варианты: <ul><li>PRESERVE ROWS- никакие доп. действия не применяются(параметр по   умолчанию)</li><li>DELETE ROWS -все строки временной таблицы удаляются в   конце каждой транзакции(по факту применяется TRUNCATE после каждого commit.     </li><li>DROP Временная таблицы удаляется(drop)  в конце транзакции </li></ul> |
|blocksize|размер блока сжатия AO-таблицы. К Heap-таблицам не применимо|
Подробнее про блоки:
Greenplum  использует общую буферную область (**Shared  buffer**) в качестве промежуточного буфера памяти. Backend-процесс взаимодействует со средним уровнем. Буфер в общей памяти заменяется файлом на диске.
![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/shared_buffer_1.jpg?raw=true)

Что происходит в общем буфере? Greenplum собирает данные в блоки:
![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/shared_buffer2.jpg?raw=true)
Таблица сопоставления (mapping  table) находит блок, соответствующий блоку общего буфера (Shared  buffer). Если содержимое признаётся недействительным, данные загружаются в блок общего буфера с помощью операции с нижним файлом (lower  file  operation). Если действительным — читается напрямую.
```sql
--самый простой вид create table
drop table  IF  EXISTS student60.test3;
create table IF NOT EXISTS   student60.test3 (
 id int,
 str_info text
)
distributed by (id);--не забываем про распределение
```
#### CONSTRAINTS
Это  правила, применяемые к столбцам данных таблицы. Используются, для ограничения типы и значения данных, которые могут храниться в таблице. Это дает возможность привязать возможные значения таблицы к бизнес-правилу: например, указать, что цены товаров могут быть только положительными, даже если тип данных теоретически допускает отрицательные значения. Если пользователь попытается сохранить значение, нарушающее указанные ограничения, возникнет ошибка.
|     Значение            |     Описание                                                                                                                                  |
|-------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------|
|     not   null          |     Данная колонка не может иметь значение   NULL                                                                                             |
|     default             |     Обеспечивает значение по   умолчанию для колонки в случае, если данные не указаны                                                         |
|     unique              |     Все значения в данной колонке   уникальны. Замечание: доступно только в heap-таблицах                                                     |
|     primary key         |     Уникальный идентификатор каждой   записи в таблице БД. Замечание: это комбинация NOT NULL и UNIQUE, доступно   только в heap-таблицах.    |
|     foreign key         |     Уникальный идентификатор записи   в другой таблице БД. Замечание: допускается в синтаксисе, но не работает                                |
|     check               |     Гарантирует, что все значения в   колонке соответствуют определённому условию                                                             |
|     index               |     Используется для быстрого   создания и получения данных из БД                                                                             |
```sql
create table IF NOT EXISTS   student60.test3 (
    id SERIAL not null PRIMARY KEY,
	first_name VARCHAR (50) not null default('Vasya')  ,
	last_name VARCHAR (50),
	birth_date DATE CHECK (birth_date > '1900-01-01'),
	joined_date DATE CHECK (joined_date > birth_date),
	salary numeric CHECK(salary > 0)
)
distributed by (id);
```
### Копирование полной структуры таблицы
```sql
create table    student60.test4 (like  student60.test3)
distributed randomly;
```
#### create table as
Создаёт таблицу из результата запроса.

Удобно, например, при аналитике , когда нет желания явно указывать типы данных(при таком подходе они определятся автоматически.
```sql
create table student60.test5 as
select concat(first_name,'_' ,last_name) as fio
       ,salary
from student60.test3 limit 2
distributed randomly;
```
#### Пример с with
```sql
create unlogged table student60.test3 (
 id int,
 str_info text
)
with (oids=true,
     fillfactor=10)
distributed by (id);
```
#### Пример с партициями
```sql
CREATE TABLE student60.t5 (
	i int4 NULL,
	j int4 NULL,
	k int4 NULL,
	l int4 NULL
)
WITH (
	appendonly=true,
	orientation=column
)
DISTRIBUTED RANDOMLY
PARTITION BY RANGE(i)
          SUBPARTITION BY RANGE(j) 
          (
          PARTITION p1 START (1) END (2) WITH (appendonly='true', orientation='column') 
                    COLUMN i ENCODING (compresstype=none, blocksize=32768, compresslevel=0) 
                    COLUMN j ENCODING (compresstype=none, blocksize=32768, compresslevel=0) 
                    COLUMN k ENCODING (compresstype=none, blocksize=32768, compresslevel=0) 
                    COLUMN l ENCODING (compresstype=none, blocksize=32768, compresslevel=0)
                  (
                  SUBPARTITION sp1 START (1) END (2) WITH (appendonly='true', orientation='column') 
                            COLUMN i ENCODING (compresstype=zlib, blocksize=65536, compresslevel=1) 
                            COLUMN j ENCODING (compresstype=none, blocksize=32768, compresslevel=0) 
                            COLUMN k ENCODING (compresstype=none, blocksize=32768, compresslevel=0) 
                            COLUMN l ENCODING (compresstype=none, blocksize=32768, compresslevel=0)
                  ), 
          PARTITION p2 START (2) END (3) INCLUSIVE WITH (appendonly='true', orientation='column') 
                    COLUMN i ENCODING (compresstype=none, blocksize=32768, compresslevel=0) 
                    COLUMN j ENCODING (compresstype=none, blocksize=32768, compresslevel=0) 
                    COLUMN k ENCODING (compresstype=none, blocksize=32768, compresslevel=0) 
                    COLUMN l ENCODING (compresstype=none, blocksize=32768, compresslevel=0)
                  (
                  SUBPARTITION sp1 START (1) END (2) WITH (appendonly='true', orientation='column') 
                            COLUMN i ENCODING (compresstype=rle_type, compresslevel=1, blocksize=32768) 
                            COLUMN j ENCODING (compresstype=none, blocksize=32768, compresslevel=0) 
                            COLUMN k ENCODING (blocksize=8192, compresstype=none, compresslevel=0) 
                            COLUMN l ENCODING (compresstype=none, blocksize=32768, compresslevel=0)
                  )
          );
```
## Представления (view)
**View** - это сохраненный запрос , с результатом которого можно работать как с таблицей.  Представление лишено физической материализации, поэтому указанный запрос будет выполняться при каждом обращении к представлению.

Преимущества использования представлений:

- дополнительный уровень безопасности данных (пользователи могут не иметь прямого доступа к базовым таблицам)
- можно скрыть сложность запроса и структур базовых таблиц. Это добавляет модульность и лаконичность при дальнейшем использовании сложно устроенных объектов
- разделение схем представления и хранения данных
- представлениях не требуется дополнительное дисковое пространство (для обычных)
```sql
--создание представления
CREATE VIEW pg_comedies  AS
SELECT *
FROM comedies
WHERE classification =  'PG‘;
--пример использования
SELECT *  FROM pg_comedies  ;
```
### Материализованные представления
- сохраняют результат запроса на диск
- можно обращаться как к обычным таблицам
- содержит данные актуальные на момент последнего обновления
- обновляется по запросу пользователя REFRESH MATERIALIZED VIEW
- могут значительно ускорить доступ к данным

Есть возможность указывать опции хранения как для обычных таблиц (WITH (applendonly=true, compresstype=zstd)). В конце DISTRIBUTED ,,,,;  
Так же можно создавать индексы как для обычной таблицы.
```sql
CREATE MATERIALIZED VIEW table_name
[ (column_name [, ...] ) ]
[ WITH ( storage_parameter [= value] [, ... ] ) ]
[ TABLESPACE tablespace_name ]
AS query
[ WITH [ NO ] DATA ] – выполнять запрос и заполнять данными при создании  или нет
[DISTRIBUTED {| BY column [opclass], [ ... ] | RANDOMLY | REPLICATED }]
```
Для обновления данных
```sql
REFRESH MATERIALIZED VIEW <view name>
```
Временно ограничить доступ пользователей к не актуальным данным:
```sql
REFRESH MATERIALIZED VIEW  test_sales  WITH  NO  DATA;
SELECT  *  FROM  test_sales;
-- ERROR пока не обновим стандартным способом
```

## Полиморфное хранилище
GreenPlum позволяет в рамках одной таблицы использовать  разные storage options(разные варианты хранения:  heap,append optimized(row/column) c различными опциями сжатия и external tables(внешние таблицы).
Основная идея - разделить данные на:
 - **горячие** -часто обновляются или участвуют в запросах, критична скорость выполнения обновлений данных и операции чтения
 - **холодные** - редко используются в запросах и соответсвенно скорость чтения некритична и можно(нужно) оптимизировать стоимость хранения(за счёт сжатия) или перемещения в более дешевое хранилище/ систему(например в  hadoop).

![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/poly_storage.jpg?raw=true)
В GreenPlum для организации полиморфного хранения используются партиции, для каждой из которых можно выбрать нужный вид хранения и сжатия.
**Пример**:
```sql
CREATE TABLE student60.sales (id int, date date, amt decimal(10,2))
WITH (appendonly=false)
DISTRIBUTED BY (id)
PARTITION BY RANGE (date)
( partition hot START (date '2022-01-01') INCLUSIVE
   END (date '2222-01-01') EXCLUSIVE
   --EVERY (INTERVAL '1 month') 
   );
  ALTER TABLE student60.sales ADD PARTITION warm
    START (date '2021-08-01') INCLUSIVE 
    END (date '2022-01-01') exclusive
    WITH (appendonly=true, orientation=column, compresstype=zstd, compresslevel=5)
   ;
  ALTER TABLE student60.sales ADD PARTITION cold
    START (date '1900-01-01') INCLUSIVE 
    END (date '2021-08-01') exclusive
   WITH (appendonly=true, orientation=column, compresstype=rle_type)
```
## Внешние таблицы(external tables)

 метаобъект, предназначенный для доступа к данным, хранящимся вне GreenPlum.
 - ВТ не хранят данные. Данные запрашиваются или отправляются при каждом запросе заново.
 - ВТ могут использоваться в запросах как обычные таблицы.
 - ВТ на чтение всегда вызывают REDISTRIBUTE MOTION при запросе данных,на запись – не всегда
 - Доступно логирование ошибочных записей

ВТ бывают:

 - READABLE и WRITABLE – читать и писать в один объект нельзя.
 - WEB и обычные.

**WEB** – только для протокола HTTP и запуска системных команд в окружении ОС кластера.
Обычные предназначены для подключения к файлам или другим системам.
![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/external.jpg?raw=true)

### Протоколы
#### Для WEB внешних таблиц


|             |                                                                                  |
|----------------|------------------------------------------------------------------------------------|
|     http://    |     доступ к данным на   HTTP-сервере. Только чтение. HTTPS не поддерживается.     |
|     EXECUTE    |     Выполнение команды в   операционной системе кластера.                          |


#### Для простых внешних таблиц

|                    |                                                                                                          |
|--------------------|----------------------------------------------------------------------------------------------------------|
|     file://        |     доступ к файлам на ФС   сегментов. С мастера данные получить нельзя. Для простых внешних таблиц.     |
|     gpfdist://     |     gpfdist:// - доступ   к GPFDIST-серверу. Для простых внешних таблиц.                                 |
|     gpfdists://    |     gpfdists:// - доступ   к SSL-версии GPFDIST. Для простых внешних таблиц.                             |
|     s3://          |      s3:// - доступ   к файлам на Amazon S3 bucket.                                                      |
|     pxf://         |     pxf:// - доступ   к внешним ресурсам через Platform eXtension   Framework.(например, к Hadoop)       |
|     custom         |     Можно создавать свои вои протоколы при помощи C- библиотек.                                          |

Синтаксис:
```sql
CREATE [READABLE] EXTERNAL TABLE table_name
( column_name data_type [, ...] | LIKE other_table )
LOCATION (protocol://location[options]' [, ...])
[ON MASTER] -- только для S3 и custom
FORMAT 'TEXT' 
[( [HEADER] -- игнорировать первую строку. Недоступно для PXF
[DELIMITER [AS] 'delimiter' | 'OFF'] 
[NULL [AS] 'null string']
[ESCAPE [AS] 'escape' | 'OFF']
[NEWLINE [ AS ] 'LF' | 'CR' | 'CRLF']
[FILL MISSING FIELDS] )] -- если не хватает столбцов, заполнять NULL
Обычная внешняя таблица на чтение
| 'CSV'
[( [HEADER]
[QUOTE [AS] 'quote'] 
[DELIMITER [AS] 'delimiter']
[NULL [AS] 'null string']
[FORCE NOT NULL column [, ...]]
[ESCAPE [AS] 'escape']
[NEWLINE [ AS ] 'LF' | 'CR' | 'CRLF']
[FILL MISSING FIELDS] )]
| 'CUSTOM' (Formatter=<formatter_specifications>)
[ ENCODING 'encoding' ] -- кодировка
[ [LOG ERRORS] SEGMENT REJECT LIMIT count [ROWS | PERCENT] ] -- логировать ли ошибки и число допустимых
```
### PXF
- Platform Extension Framework (PXF) – это отдельное ПО, выступающее посредником между сегментами кластера и сторонними системами (базами данных, хранилищами). 
- Реализован как отдельный JAVA-сервис, работающий на всех сегмент-серверах под своим пользователем (PXF). 
- Запускается одна копия PXF на каждом сегментном сервере, требует перезагрузки при добавлении нового JDBC драйвера
- Сегменты ADB обращаются к своей копии через через REST. 
- Содержит подключаемые модули – коннекторы и плагины, необходимые для доступа к внешним системам. 
- Возможность чтения и записи данных зависит от плагина. Бывают однонаправленными и двунаправленными.
- Можно разрабатывать свои коннекторы

### User Impersonation

![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/impersonation.jpg?raw=true)

По умолчанию работа с внешней системой идет от имени самого PXF.

**User  Impersonation** позволяет делать это от имени пользователя, выполняющего запрос. Работает для соединений с Hadoop и по JDBC (для этого требуется конфигурация **jdbc-site.xml**)

## Выполнение запроса
![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/client_master.jpg?raw=true)
- Запросы направляются клиентом мастер-сегменту. 
- PostgreSQL listener на мастере принимает входящие подключения (стандартный порт – 5432). 
- Парсер (Query Parser) проверяет синтаксис, семантику и генерирует дерево запроса для оптимизатора (Query Optimizer). 
- Мастер может выполнять некоторые финальные операции с данными – агрегации, сортировки и т.д., но основная работа происходит на праймари сегментах сегментных серверов. 
- Запросы пишутся на декларативном языке SQL

![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/gporca.jpg?raw=true)

- В системе есть два оптимизатора: GPORCA и Postgres, они генерируют планы. 
- Оптимизатор GPORCA был специально разработан для GP и формирует более эффективные планы запросов в большинстве случаев. 
-  PostgreSQL query optimizer умеет обрабатывать случаи, с которыми не справляется GPORCA, переключение при этом происходит автоматически. 
- Каждый план имеет стоимость, план с меньшей стоимостью передаётся диспетчеру.
![enter image description here](https://github.com/Rayveni/blog/blob/main/articles/greenplum%20express/img/master_host2.jpg?raw=true)

- Диспетчер передаёт план запроса сегментам. 
- Аллоцирует ресурсы на сегментах согласно плану. 
-  После выполнения работы сегментами аккумулирует финальный результат для передачи клиенту на мастере.
- Шаги плана на сегментах выполняют исполнители запросов (Query Executor). 
- В ходе выполнения исполнители могут обмениваться промежуточными результатами с исполнителями на других сегментах. 
- Каждый исполнитель запускает для запроса несколько процессов (Worker). 
- Результаты выполнения запросов на сегментах передаются на мастер, где происходит финальная сборка и выдача результата
## Spill файлы и оптимизаторы
это некоторый генерируемый дополнительный объем данных на жестком диске, который используется для выполнения запроса.

Спиллы появляются, когда для запроса нужно хранить данных больше, чем предоставлено оперативной памятью. Например, есть запрос, который для выполнения требует 650 Гб рабочей памяти, однако под запрос выделено 500 Гб оперативной памяти. В итоге 650 − 500 = 150 Гб — столько требуется сверх оперативной памяти. Именно этот объем сгенерируется в виде спиллов.

### Оптимизаторы

По умолчанию используется оптимизатор GPORCA, можно переключить на Postgres, например, на время сессии: **set optimizer = off;**
 Как правило, GPORCA показывает лучшие результаты в следующих случаях:
-  Запросы, которые содержат CTE, в т.ч. вложенные. 
   - Запросы, которые содержат подзапросы: 
   -  CSQ, которые могут обращаться к таблице из внешнего запроса, пропуская промежуточный подзапрос (skip-level correlation references). 
   - CSQ содержащие логическое условие OR. 
   - CSQ с агрегатами и неравенством. 
- Запросы к партиционированным таблицам

GPORCA не поддерживает оператор  **merge**.

## Common Table Expressions(CTE)
- Можно представить как временное представление, которое существует только на время выполнения запроса; 
- Внутри запроса определяются с помощью параметра WITH
-  Помогают разбить большой запрос с подзапросами на меньшие части, улучшая читабельность кода; 
- Могут улучшать производительность запросов, выполняя код внутри CTE только один раз; 
-  Могут быть использованы при выполнение команд SELECT, INSERT, UPDATE или DELETE ; 
- Могут быть использованы предикаты из внешнего запроса (GPORCA); 
-  Поддерживаются рекурсивные (только Postgres query optimizer ) и вложенные CTE (GPORCA)

```sql
WITH branch_filter AS (   --фильтруем филиалы
			SELECT branch_id 
			    FROM branches 
		    WHERE branch_name LIKE '%a' 
),
client_filter AS   --отфильтровываем сегмент клиента мас
			(SELECT customer 
			     FROM customers  
				INNER JOIN active_clients AS  a_clients 
					ON a_clients.id=customers.id   
			WHERE customers.segment='mass'
			)
SELECT sales.* 
FROM sales 
	INNER JOIN client_filter 
		ON client_filter.customer=sales.customer
	INNER  JOIN branch_filter
		ON branch_filter.branch_id=sales.branch_id
```
## План запроса
- строится оптимизатором (планировщиком)
- показывает последовательность физических операций с данными для получения результата запроса
- основан на предварительно собранной статистике (количество строк в таблице и характер распределения данных)
- отображает стоимость (количественная характеристика, связанная со временем запроса) каждого шага и запроса в целом
- оптимизатор выбирает план с наименьшей стоимостью

### Explain
- запрос не выполняется
- план запроса с оценочной информацией о выполнении, построенный на основе статистики о таблицах(если статистика неактуальна- может не отражать реального положения вещей)
### Explain  Analyze
-  запрос выполняется
-  план запроса с фактической информацией о выполнении: время выполнения каждого шага, количество обработанных записей, использованная память
```sql
EXPLAIN ANALYZE  SELECT *  FROM pg_comedies
```

## Статистика
Актуальная статистика является необходимым условием оптимального построения плана для выполнения запроса. 
Без неё планы будут строиться неверно и могут быть проблемы с распределением памяти. 
Когда необходимо запускать сбор статистики: 
- После загрузки данных. 
- После создания индексов. 
- После операция INSERT, UPDATE и DELETE, которые привели к значительному изменению данных. 

Примерный объём изменений в таблице, при котором следует обновить статистику – 0.5%. 
В базовой конфигурации статистика собирается только при первой вставке данных в таблицу. 
При последующих операциях с данными необходимо вручную обновлять статистику при помощи команды ANALYZE.
### Команда Analyze
- Без параметров – запускает сбор статистики по всем таблицам в БД. 
-  С указанием имени таблицы – собирает статистику только по заданной таблице. 
-  С указанием таблицы и колонок – собирает статистику только по указанным колонкам. 
- Сохраняет статистику в системную таблицу pg_statistic. 
- pg_stats – представление, которое покажет, какая статистика была собрана для таблицы. 
- pg_stat_operations - представление, которое подскажет, какие операции и когда были над объектом в том числе и ANALYZE

## Обслуживание таблиц
Удаленные строки :занимают место на диске- увеличивают время чтения данных

**VACUUM, VACUUM FULL** - очистка таблиц от неактуальных записей.

**VACUUM** - помечает место, которые занимали удаленные строки как потенциально свободные. Физически, эти строки не удаляются, но при вставке новых строк в таблицу они будут вставлены на место удаленных. Не требует блокировки на таблицу

**VACUUM FULL** - делает все тоже самое, но еще удаляет записи и сжимает таблицу. На освободившееся место физически переносятся строки, которые уже были в этой таблице. Именно поэтому физически размер таблицы становится меньше. Требуется эксклюзивная блокировка. Иногда скопировать таблицу проще и быстрее. На мой взгляд, лучше не применять.

Для Append-optimized таблиц:

- **VACUUM** ведет себя как VACUUM FULL, если bloat (раздутие. соотношение не актуальных строк к актуальным) > 10%
-  **VACUUM FULL** (или VACUUM bloat > 10%):сжимает таблицу, копируя данные в новый файл, и удаляет старый не блокируя таблицу (кроме кратковременного момента переключения на новый файл)

## Рекомендации
- запускать VACUUM после массовых изменений (UPDATE/DELETE)
- при регулярном VACUUM в команде VACUUM FULL нет необходимости
- VACUUM FULL может потребоваться для схлопывания больших пустот в таблицах (после VACUUM) и исключения перекосов вычисления
- системные каталоги тоже требуют регулярный VACUUM - частота зависит от количества DDL-операций
- текущий bloat отображается в представлении gp_toolkit.gp_bloat_diag

## Функции

- могут принимать на вход параметры
- могут возвращать результат в виде одной или нескольких строк
- могут не возвращать какой-либо результат, а только выполнять определенный набор операций(процедур и пользовательских триггеров в GreenPlum нет)-если тип возвращаемого значения VOID
- могут выполняться на мастере и на сегментах, в зависимости от того, как вызывается функция
- Функции в Greenplum вызываются с помощью предложения SELECT с последующим указанием имени функции и входящих параметров.

### Типы функций
- **IMMUTABLE**: говорит о том, что результат функции напрямую зависит только от ее аргументов. То есть при одинаковых входящих параметрах результат будет всегда один и тот же. Примерами таких функций являются конкатенация строк и вычисление модуля.
- **STABLE**:сообщает о том, что результат функции может меняться от транзакции к транзакции, однако он не может меняться в рамках одной транзакции. Примерами таких функций являются функции возврата текущего времени и даты.
- **VOLATILE**:используется по-умолчанию, и сообщает о том, что значение функции может меняться в ходе выполнения транзакции. Примеры таких функций: timeofday, random, setval. Используйте такие типы функций с осторожностью. Чаще всего они выполняются только на мастере.

Если вы уверены, что ваша функция относится к классу IMMUTABLE или STABLE – обязательно явно укажите это в теле функции.

### Место выполнения функции
Функции можно выполнять с помощью двух типов команд:

Select  function() ; - чаще всего будет выполняться на мастере, если не используется параметр EXECUTE ON ALL SEGMENTS.

Select  function(field) from  table; - чаще всего будет выполняться на сегментах , если не используется параметр EXECUTE ON. MASTER

Параметр EXECUTE ON указывает, где должна исполняться функция:
|     Имя атрибута               |     Описание                                                                                                                                                                    |     Дополнительно                                                                                        |
|--------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
|     EXECUTE ON ANY             |     Функция может исполняться как   на мастере, так и на сегменте. Возвращает один и тот же результат вне   зависимости от места исполнения. Является значением по умолчанию    |     Greenplum   сам определяет где должна исполняться функция                                            |
|     EXECUTE ON MASTER          |     Функция должна исполняться на   мастере                                                                                                                                     |     Используйте это значение, если   внутри функции используется запрос, который обращается к таблице    |
|     EXECUTE ON ALL SEGMENTS    |     Функция должна исполняться на   сегментах                                                                                                                                   |                                                                                                          |

Функция с запросом может исполняться на сегментах если только читает данные из Replicated-таблиц или из каталога.

### Типы процедурных языков
В Greenplum все процедурные языки подразделяются на два типа по признаку доверия.

Если язык относится к типу Trusted – то это означает, что при использовании данного языка пользователь не может вносить изменения на уровне файловой системы, например выходить в командную оболочку SHELL и так далее, то есть в этом случае пользователь не может нанести вред системе.

Если язык относится к типу Untrusted – то использование данного языка может нанести вред СУБД. Создание функций на таких языках доступно только ролям с правами суперпользователя, а выполнение таких функций доступно всем.

Следует отметить, что у некоторых языков есть две версии – trusted и untrusted.

- PL/pgSQL – trusted (установлен по-умолчанию)
- PL/R – untrusted
- PL/Python – untrusted (установлен по-умолчанию)
- PL/Container (доступны Python и R) – trusted (установлен по-умолчанию)
- PL/Java – trusted и untrusted
- PL/Perl – trusted и untrusted
- PL/C – trusted

## Источники

- https://cloud.yandex.ru/docs/managed-greenplum/concepts/tables
- https://www.bigdataschool.ru/
- ArenaData
- https://idyakonoff.ru/posts/pg-greenplum/
- https://habr.com/
- https://habr.com/ru/company/southbridge/blog/708124/
- https://docs.vmware.com/en/VMware-Tanzu-Greenplum/index.html
